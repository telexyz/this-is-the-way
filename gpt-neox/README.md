
**Large corpus:** Use https://github.com/EleutherAI/gpt-neox#datasets to convert .jsonl into .bin and .idx
```sh
python3 prepare_data.py -d ./data

# .zst means that the archive is compressed by zstd.
python3 preprocess_data.py \
            --input ./data/mydataset.jsonl.zst \
            --output-prefix ./data/mydataset \
            --vocab ./data/myvocab.json \
            --dataset-impl mmap \
            --tokenizer-type TiktokenTokenizer \
            --append-eod

python3 preprocess_data.py --help # for more info
```

```
{"meta": {"ID": 101}, "text": "This is the first document."}
{"meta": {"ID": 102}, "text": "Hello\nWorld"}
{"meta": {"ID": 103}, "text": "1+1=2\n1+2=3\n2+2=4"}
```
generated by code like this:
```
ss = json.dumps({"meta": meta, "text": text}, ensure_ascii=False)
out.write(ss + "\n")
```
